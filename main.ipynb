{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Define Layer</b> 3 types of layer class are defined : (1) input layer, (2) dense layer, and (3) activation layer</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input_layer:\n",
    "    def __init__(self, input_depth, input_width=1):\n",
    "        self.TYPE = 'INPUT'\n",
    "        self.SHAPE = (input_depth, input_width)\n",
    "        a = list()\n",
    "        for i in range(self.SHAPE[0]):\n",
    "            tmp = []\n",
    "            for j in range(self.SHAPE[1]):\n",
    "                tmp.append(f'I_{i},{j}')\n",
    "            a.append(tmp)\n",
    "        self.VALUE = a\n",
    "\n",
    "class Dense_layer:\n",
    "    def __init__(self,size_of_node):\n",
    "        self.TYPE = 'DENSE'\n",
    "        self.SIZE = size_of_node\n",
    "        self.INPUT_SIZE = 0\n",
    "        self.WEIGHT = list()\n",
    "        self.BIAS = list()\n",
    "\n",
    "    def __call__(self,input_size,rank=None):\n",
    "        self.INPUT_SIZE = input_size\n",
    "        \n",
    "        for row in range(self.SIZE):\n",
    "            weight_tmp = list()\n",
    "            for col in range(self.INPUT_SIZE):\n",
    "                weight_tmp.append(f'W{rank}_{row},{col}')\n",
    "            self.WEIGHT.append(weight_tmp)\n",
    "\n",
    "        bias_tmp = list()\n",
    "        for row in range(self.SIZE):\n",
    "            bias_tmp.append(f'B{rank}_{row}')\n",
    "        self.BIAS = bias_tmp\n",
    "        return self\n",
    "\n",
    "class Activation_layer:\n",
    "    def __init__(self, function):\n",
    "        self.TYPE = 'ACTIVATION'\n",
    "        self.function = function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Define Model </b> Design a model that takes layers as parameters. Layers will be stacked in as list</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_model:\n",
    "    def __init__(self, *list_of_layers):\n",
    "        self.dense_counter = 0\n",
    "        self.activation_counter = 0\n",
    "        self.input_size = None\n",
    "        self.model_layer = {}\n",
    "\n",
    "        for layer in list_of_layers:\n",
    "            if layer.TYPE == 'INPUT':\n",
    "                self.model_layer['input_layer'] = layer.VALUE\n",
    "                self.input_size = layer.SHAPE[1]\n",
    "\n",
    "            elif layer.TYPE == 'DENSE':\n",
    "                self.dense_counter += 1\n",
    "                layer(self.input_size,self.dense_counter)\n",
    "                self.model_layer[f'dense_layer_{self.dense_counter}'] = (layer.WEIGHT, layer.BIAS)\n",
    "                self.input_size = layer.SIZE\n",
    "\n",
    "            elif layer.TYPE == 'ACTIVATION':\n",
    "                self.activation_counter += 1\n",
    "                self.model_layer[f'activation_layer_{self.activation_counter}'] = layer.function\n",
    "    def summary(self):\n",
    "        for layer in self.model_layer.keys():\n",
    "            print(f'{layer} : {self.model_layer[layer]}')\n",
    "\n",
    "    def forward(self):\n",
    "        self.input_layer = []\n",
    "        for key in self.model_layer.keys():\n",
    "            if 'input' in key:\n",
    "                self.input_layer = self.model_layer[key]\n",
    "                # self.input_depth = len(self.model_layer[key])\n",
    "                # self.input_width = len(self.model_layer[key][0])\n",
    "                \n",
    "            elif 'dense' in key:\n",
    "                signal_out = list()\n",
    "                weight_layer = self.model_layer[key][0]\n",
    "                bias_layer = self.model_layer[key][1]\n",
    "                depth = len(weight_layer)\n",
    "                \n",
    "                for row in range(depth):\n",
    "                    mul_str = ''\n",
    "                    for input_row in range(len(self.input_layer)):\n",
    "                        for input_col in range(len(self.input_layer[0])):\n",
    "                            mul_str += weight_layer[row][input_row] +'*'+ self.input_layer[input_row][input_col]+ '+' + bias_layer[row] + '+'\n",
    "                    mul_str = mul_str[:-1]\n",
    "                    signal_out.append([mul_str])\n",
    "                self.input_layer = signal_out\n",
    "            \n",
    "            elif 'activation' in key:\n",
    "                signal_out = self.input_layer\n",
    "                for row in range(len(self.input_layer)):\n",
    "                    for col in range(len(self.input_layer[0])):\n",
    "                        signal_out[row][col] = f'{self.model_layer[key]}({self.input_layer[row][col]})'\n",
    "                self.input_layer = signal_out\n",
    "        \n",
    "        return signal_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Config Model </b> Define input and Output size and stack layers </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLE SETTING AND LIMITER\n",
    "INPUT_SIZE = 4\n",
    "OUTPUT_SIZE = 10\n",
    "\n",
    "# CONFIG MODEL\n",
    "model = Sequential_model(\n",
    "    Input_layer(1,INPUT_SIZE),\n",
    "    Dense_layer(2),\n",
    "    Activation_layer('Relu'),\n",
    "    Dense_layer(4),\n",
    "    Activation_layer('Relu'),\n",
    "    Dense_layer(OUTPUT_SIZE),\n",
    "    Activation_layer('Softmax')\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Limiter </b> Just in Case, if the parameter is too large, numerical gradient will not work. To prevent OOM error, limit the size of the nodes for each layers</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIREMENT : PASSED\n"
     ]
    }
   ],
   "source": [
    "# MODEL LIMITER\n",
    "for key in model.model_layer.keys():\n",
    "    if 'dense' in key:\n",
    "        if len(model.model_layer[key][0])*len(model.model_layer[key][0][0]) < 100:\n",
    "            pass\n",
    "        else:\n",
    "            raise MemoryError(f'too large to calculate numerical gradient in {key} ')\n",
    "print('REQUIREMENT : PASSED')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Model Summary </b> model layers are saved as dictionary</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer : [['I_0,0', 'I_0,1', 'I_0,2', 'I_0,3']]\n",
      "dense_layer_1 : ([['W1_0,0', 'W1_0,1', 'W1_0,2', 'W1_0,3'], ['W1_1,0', 'W1_1,1', 'W1_1,2', 'W1_1,3']], ['B1_0', 'B1_1'])\n",
      "activation_layer_1 : Relu\n",
      "dense_layer_2 : ([['W2_0,0', 'W2_0,1'], ['W2_1,0', 'W2_1,1'], ['W2_2,0', 'W2_2,1'], ['W2_3,0', 'W2_3,1']], ['B2_0', 'B2_1', 'B2_2', 'B2_3'])\n",
      "activation_layer_2 : Relu\n",
      "dense_layer_3 : ([['W3_0,0', 'W3_0,1', 'W3_0,2', 'W3_0,3'], ['W3_1,0', 'W3_1,1', 'W3_1,2', 'W3_1,3'], ['W3_2,0', 'W3_2,1', 'W3_2,2', 'W3_2,3'], ['W3_3,0', 'W3_3,1', 'W3_3,2', 'W3_3,3'], ['W3_4,0', 'W3_4,1', 'W3_4,2', 'W3_4,3'], ['W3_5,0', 'W3_5,1', 'W3_5,2', 'W3_5,3'], ['W3_6,0', 'W3_6,1', 'W3_6,2', 'W3_6,3'], ['W3_7,0', 'W3_7,1', 'W3_7,2', 'W3_7,3'], ['W3_8,0', 'W3_8,1', 'W3_8,2', 'W3_8,3'], ['W3_9,0', 'W3_9,1', 'W3_9,2', 'W3_9,3']], ['B3_0', 'B3_1', 'B3_2', 'B3_3', 'B3_4', 'B3_5', 'B3_6', 'B3_7', 'B3_8', 'B3_9'])\n",
      "activation_layer_3 : Softmax\n"
     ]
    }
   ],
   "source": [
    "# MODEL SUMMARY\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Error Calculation </b> MSE is used as error for convinience</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE MSE ERROR\n",
    "output = model.forward()\n",
    "\n",
    "truth = [f'T{i}' for i in range(OUTPUT_SIZE)]\n",
    "\n",
    "tmp = ''\n",
    "for i in range(OUTPUT_SIZE):\n",
    "    tmp += f'({truth[i]}-{output[i][0]})^2 +'\n",
    "\n",
    "mse_error = f'1/2 * [{tmp[:-1]}]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Numerical Gradient Calculation</b> calculates gradients for the error on each node in each layers</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMERICAL GRADIENT\n",
    "import copy\n",
    "numerical_gradient = copy.deepcopy(model.model_layer)\n",
    "\n",
    "for key in model.model_layer.keys():\n",
    "    if 'input' in key:\n",
    "        pass\n",
    "\n",
    "    elif 'dense' in key:\n",
    "        weight = model.model_layer[key][0]\n",
    "        for row in range(len(weight)):\n",
    "            for col in range(len(weight[0])):\n",
    "                word = weight[row][col]\n",
    "                tmp1 = output\n",
    "                tmp2 = output\n",
    "                numerical_gradient[key][0][row][col] = f\"{tmp.replace(word, f'({word} + H)')} - {tmp.replace(word, f'({word} - H)')} / 2H\"\n",
    "\n",
    "        bias = model.model_layer[key][1]\n",
    "        for row in range(len(bias)):\n",
    "            word = bias[row]\n",
    "            tmp1 = output\n",
    "            tmp2 = output\n",
    "            numerical_gradient[key][1][row] = f\"{tmp.replace(word, f'({word} + H)')} - {tmp.replace(word, f'{word} - H')} / 2H\"\n",
    "            \n",
    "    elif 'activation' in key:\n",
    "        word = model.model_layer[key]\n",
    "        numerical_gradient[key] = f'derivative of {word}'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Weight update</b> LR : Learning Rate</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE\n",
    "updated_model_layer = copy.deepcopy(model.model_layer)\n",
    "for key in model.model_layer.keys():\n",
    "    if 'input' in key:\n",
    "        pass\n",
    "\n",
    "    elif 'dense' in key:\n",
    "        weight = model.model_layer[key][0]\n",
    "        for row in range(len(weight)):\n",
    "            for col in range(len(weight[0])):\n",
    "                word = weight[row][col]\n",
    "                updated_model_layer[key][0][row][col] = f'{word} -LR*{numerical_gradient[key][0][row][col]}'\n",
    "        \n",
    "        bias = model.model_layer[key][1]\n",
    "        for row in range(len(bias)):\n",
    "            word = bias[row]\n",
    "            updated_model_layer[key][1][row] = f'{word} - LR*{numerical_gradient[key][1][row]}'\n",
    "\n",
    "    elif 'activation' in key:\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>View updated weight</b> since the equation is very long, it is recommanded to specify the exact layer you are looking for</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eq = updated_model_layer['dense_layer_1'][0][0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>save and load equation</b> try python prompt does not print all equation</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SAVE EQUATION IN PICKLE\n",
    "import pickle\n",
    "filename = './equation_for_updating_single_node.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(eq,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD EQUATION FROM PICKLE\n",
    "with open(filename,'rb') as f:\n",
    "    x = pickle.load(f)\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep_Scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4b549291e0e86b191a7dcb7a5876a76793a5689e1e99b0448ba3502e0564c05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
